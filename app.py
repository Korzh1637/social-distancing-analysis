import os
os.environ['YOLO_VERBOSE'] = 'False'
os.environ['ULTRALYTICS_HUB'] = 'False'

from flask import Flask, render_template, Response, jsonify, request
import cv2
import numpy as np
import threading
import time
import tempfile
import uuid
from datetime import datetime
import base64
import json

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
detector = None
tracker = None
logger = None
metrics_calc = None
processing = False
current_frame = None
frame_lock = threading.Lock()
video_source = 'test'
current_video_path = None
cap = None

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
current_metrics = {
    'people_count': 0,
    'violations_count': 0,
    'density': 0.0,
    'risk_level': '–ù–∏–∑–∫–∏–π',
    'active_violations': [],
    'movement_metrics': {},
    'zone_type': 'default',
    'timestamp': datetime.now().isoformat()
}

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
try:
    from core.detector import PeopleDetector
    from core.tracker import PeopleTracker
    from utils.logger import EventLogger, EventType
    from utils.metrics import MetricsCalculator, RiskLevel
    components_loaded = True
    print("‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
    components_loaded = False

def initialize_components():
    global detector, tracker, logger, metrics_calc
    
    if not components_loaded:
        print("‚ùå –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        return False
    
    try:
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞...")
        detector = PeopleDetector()
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞...")
        tracker = PeopleTracker()
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞...")
        logger = EventLogger()
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫...")
        metrics_calc = MetricsCalculator()
        print("‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
        import traceback
        traceback.print_exc()
        return False

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
components_initialized = initialize_components()

def cleanup_video_capture():
    global cap
    if cap is not None:
        cap.release()
        cap = None

def initialize_video_source(source_type, video_path=None):
    global cap, video_source, current_video_path
    
    cleanup_video_capture()
    
    video_source = source_type
    current_video_path = video_path
    
    if source_type == 'camera':
        camera_index = 0
        cap = cv2.VideoCapture(camera_index)
        if cap.isOpened():
            print(f"‚úÖ –ö–∞–º–µ—Ä–∞ –Ω–∞–π–¥–µ–Ω–∞ (–∏–Ω–¥–µ–∫—Å {camera_index})")
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 25)
            return True
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—Ç–∞—é—â—É—é –∫–∞–º–µ—Ä—É")
            return False
        
    elif source_type == 'video_file' and video_path:
        cap = cv2.VideoCapture(video_path)
        if cap.isOpened():
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
            print(f"‚úÖ –í–∏–¥–µ–æ—Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {video_path}")
            print(f"   FPS: {fps}, –ö–∞–¥—Ä–æ–≤: {frame_count}")
            return True
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª: {video_path}")
            return False
    
    elif source_type == 'test':
        print("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
        return True
    
    return False

def process_video_stream():
    global processing, current_frame, current_metrics, video_source, cap
    
    print(f"üé• –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ. –ò—Å—Ç–æ—á–Ω–∏–∫: {video_source}")
    
    if not initialize_video_source(video_source, current_video_path):
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–∏–¥–µ–æ")
        processing = False
        return
    
    frame_count = 0
    last_log_time = time.time()
    
    while processing:
        try:
            frame = None
            
            if video_source in ['camera', 'video_file'] and cap and cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    if video_source == 'video_file':
                        # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª
                        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                        print("üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞")
                        continue
                    else:
                        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã")
                        break
                
                frame = cv2.resize(frame, (640, 480))
            else:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∫–∞–¥—Ä
                frame = generate_test_frame(frame_count)
                time.sleep(0.04)  # –ò–º–∏—Ç–∞—Ü–∏—è 25 FPS
            
            if frame is None:
                print("‚ùå –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –∫–∞–¥—Ä")
                continue
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
            print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ {frame_count}...")
            detections = detector.detect(frame)
            print(f"   –ù–∞–π–¥–µ–Ω–æ –¥–µ—Ç–µ–∫—Ü–∏–π: {len(detections)}")
            
            tracks = tracker.update(detections, frame)
            print(f"   –ê–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤: {len(tracks)}")
            
            # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            movement_metrics = metrics_calc.calculate_movement_metrics(tracks)
            distances, violations = metrics_calc.calculate_pairwise_distances(
                tracks, frame.shape[:2], movement_metrics
            )
            
            zone_type = metrics_calc.zone_analyzer.detect_zone_type(
                tracks, frame.shape[:2], movement_metrics
            )
            
            density = metrics_calc.calculate_density(len(tracks))
            risk_level = metrics_calc.assess_risk_level(len(violations), density, zone_type.value)
            
            real_violations = [v for v in violations if v.get('is_real_violation', False)]
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            with frame_lock:
                current_metrics.update({
                    'people_count': len(tracks),
                    'violations_count': len(real_violations),
                    'density': density,
                    'risk_level': risk_level.value,
                    'active_violations': real_violations[:5],
                    'movement_metrics': movement_metrics,
                    'zone_type': zone_type.value,
                    'timestamp': datetime.now().isoformat(),
                })
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            result_frame = tracker.draw_tracks(frame, tracks)
            
            # –†–∏—Å—É–µ–º –Ω–∞—Ä—É—à–µ–Ω–∏—è
            for violation in real_violations[:3]:
                track1 = next((t for t in tracks if t['track_id'] == violation['person1']), None)
                track2 = next((t for t in tracks if t['track_id'] == violation['person2']), None)
                
                if track1 and track2:
                    cv2.line(result_frame, track1['center'], track2['center'], (0, 0, 255), 2)
                    mid_point = (
                        (track1['center'][0] + track2['center'][0]) // 2,
                        (track1['center'][1] + track2['center'][1]) // 2
                    )
                    cv2.putText(result_frame, f"{violation['distance']:.1f}m", 
                               mid_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
            
            # –†–∏—Å—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –∫–∞–¥—Ä–µ
            draw_metrics_on_frame(result_frame, current_metrics, zone_type.value)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∂–∏–º–µ
            mode_text = {
                'camera': "–†–ï–ñ–ò–ú: –í–ï–ë-–ö–ê–ú–ï–†–ê",
                'video_file': "–†–ï–ñ–ò–ú: –í–ò–î–ï–û–§–ê–ô–õ", 
                'test': "–†–ï–ñ–ò–ú: –¢–ï–°–¢–û–í–´–ô"
            }.get(video_source, "–†–ï–ñ–ò–ú: –ù–ï–ò–ó–í–ï–°–¢–ï–ù")
            
            cv2.putText(result_frame, mode_text, (10, result_frame.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            debug_text = f"–ö–∞–¥—Ä: {frame_count} | –î–µ—Ç–µ–∫—Ü–∏–π: {len(detections)} | –¢—Ä–µ–∫–æ–≤: {len(tracks)}"
            cv2.putText(result_frame, debug_text, (10, result_frame.shape[0] - 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä
            with frame_lock:
                success, encoded_image = cv2.imencode('.jpg', result_frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
                if success:
                    current_frame = encoded_image.tobytes()
                else:
                    print("‚ùå –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–¥—Ä–∞")
            
            frame_count += 1
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
            current_time = time.time()
            if current_time - last_log_time >= 5:
                print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –∫–∞–¥—Ä–æ–≤ {frame_count}, –ª—é–¥–µ–π {len(tracks)}, –Ω–∞—Ä—É—à–µ–Ω–∏–π {len(real_violations)}")
                last_log_time = current_time
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞: {e}")
            import traceback
            traceback.print_exc()
            time.sleep(0.1)
    
    cleanup_video_capture()
    print("‚èπÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

def draw_metrics_on_frame(frame, metrics, zone_type):
    """–†–∏—Å—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –∫–∞–¥—Ä–µ"""
    y_offset = 30
    line_height = 25
    
    metrics_text = [
        f"–õ—é–¥–∏: {metrics['people_count']}",
        f"–ù–∞—Ä—É—à–µ–Ω–∏—è: {metrics['violations_count']}",
        f"–ü–ª–æ—Ç–Ω–æ—Å—Ç—å: {metrics['density']:.1f} —á–µ–ª/–º¬≤",
        f"–†–∏—Å–∫: {metrics['risk_level']}",
        f"–ó–æ–Ω–∞: {zone_type}"
    ]
    
    # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
    for i, text in enumerate(metrics_text):
        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
        cv2.rectangle(frame, (5, y_offset + i * line_height - 20), 
                     (text_size[0] + 15, y_offset + i * line_height + 5), 
                     (0, 0, 0), -1)
    
    # –¢–µ–∫—Å—Ç –º–µ—Ç—Ä–∏–∫
    for i, text in enumerate(metrics_text):
        color = (0, 255, 0) if metrics['risk_level'] == '–ù–∏–∑–∫–∏–π' else (
            (0, 255, 255) if metrics['risk_level'] == '–°—Ä–µ–¥–Ω–∏–π' else (0, 0, 255)
        )
        cv2.putText(frame, text, (10, y_offset + i * line_height),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

def generate_test_frame(frame_count):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –∫–∞–¥—Ä —Å –¥–≤–∏–∂—É—â–∏–º–∏—Å—è –æ–±—ä–µ–∫—Ç–∞–º–∏"""
    frame = np.ones((480, 640, 3), dtype=np.uint8) * 128
    
    # –°–µ—Ç–∫–∞
    for i in range(0, frame.shape[1], 50):
        cv2.line(frame, (i, 0), (i, frame.shape[0]), (50, 50, 50), 1)
    for i in range(0, frame.shape[0], 50):
        cv2.line(frame, (0, i), (frame.shape[1], i), (50, 50, 50), 1)
    
    # –î–≤–∏–∂—É—â–∏–µ—Å—è –æ–±—ä–µ–∫—Ç—ã (–ª—é–¥–∏) - —Å–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏
    objects = [
        {'pos': (100 + int(frame_count * 2) % 400, 100), 'size': (40, 80), 'color': (0, 255, 0), 'id': 1},
        {'pos': (300, 150 + int(frame_count * 1.5) % 200), 'size': (50, 100), 'color': (255, 0, 0), 'id': 2},
        {'pos': (200 + int(frame_count * 1.8) % 300, 300), 'size': (45, 90), 'color': (0, 0, 255), 'id': 3},
        {'pos': (400, 200 + int(frame_count * 1.2) % 150), 'size': (35, 70), 'color': (255, 255, 0), 'id': 4},
    ]
    
    for obj in objects:
        x, y = obj['pos']
        w, h = obj['size']
        
        # –†–∏—Å—É–µ–º —Ç–µ–ª–æ (–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫)
        cv2.rectangle(frame, (x, y), (x + w, y + h), obj['color'], -1)
        
        # –†–∏—Å—É–µ–º –∫–æ–Ω—Ç—É—Ä
        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 2)
        
        # –î–æ–±–∞–≤–ª—è–µ–º ID
        cv2.putText(frame, f"ID:{obj['id']}", (x + 5, y + 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É —Ü–µ–Ω—Ç—Ä–∞ (–¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç—Ä–µ–∫–∏–Ω–≥–∞)
        center_x = x + w // 2
        center_y = y + h // 2
        cv2.circle(frame, (center_x, center_y), 3, (255, 255, 255), -1)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
    cv2.putText(frame, "–¢–ï–°–¢–û–í–´–ô –†–ï–ñ–ò–ú - –†–ê–ë–û–¢–ê–ï–¢", (150, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(frame, "–°–∏—Å—Ç–µ–º–∞ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –¥–≤–∏–∂—É—â–∏—Ö—Å—è –ª—é–¥–µ–π", (150, 60), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    cv2.putText(frame, f"–ö–∞–¥—Ä: {frame_count}", (150, 90), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    return frame

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/current_frame')
def get_current_frame():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞ –≤ base64"""
    try:
        with frame_lock:
            if current_frame is not None:
                frame_base64 = base64.b64encode(current_frame).decode('utf-8')
                return jsonify({
                    'success': True,
                    'frame': frame_base64,
                    'timestamp': datetime.now().isoformat(),
                    'metrics': current_metrics
                })
            else:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∫–∞–¥—Ä –µ—Å–ª–∏ –Ω–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ
                test_frame = generate_test_frame(int(time.time()))
                success, buffer = cv2.imencode('.jpg', test_frame)
                if success:
                    frame_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')
                    return jsonify({
                        'success': True,
                        'frame': frame_base64,
                        'timestamp': datetime.now().isoformat(),
                        'metrics': current_metrics,
                        'is_test_frame': True
                    })
        
        return jsonify({'success': False, 'error': 'No frame available'})
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ API current_frame: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/start_processing', methods=['POST'])
def start_processing():
    global processing
    
    if processing:
        return jsonify({'status': 'error', 'message': '–û–±—Ä–∞–±–æ—Ç–∫–∞ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–∞'})
    
    if not components_initialized:
        return jsonify({'status': 'error', 'message': '–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã'})
    
    data = request.get_json() or {}
    source_type = data.get('video_source', 'test')
    video_file_path = data.get('video_file_path')
    
    if source_type == 'video_file' and not video_file_path:
        return jsonify({'status': 'error', 'message': '–ù–µ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É'})
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    global video_source, current_video_path
    video_source = source_type
    current_video_path = video_file_path
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    processing = True
    thread = threading.Thread(target=process_video_stream)
    thread.daemon = True
    thread.start()
    
    source_name = {
        'camera': '–≤–µ–±-–∫–∞–º–µ—Ä–∞',
        'video_file': '–≤–∏–¥–µ–æ—Ñ–∞–π–ª', 
        'test': '—Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º'
    }.get(source_type, source_type)
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ
    if logger:
        logger.log_event(
            EventType.INFO,
            f"–ó–∞–ø—É—â–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ. –ò—Å—Ç–æ—á–Ω–∏–∫: {source_type}",
            {'source': source_type, 'file_path': video_file_path}
        )
    
    return jsonify({
        'status': 'success', 
        'message': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞ ({source_name})',
        'video_source': source_type
    })

@app.route('/api/stop_processing', methods=['POST'])
def stop_processing():
    global processing
    
    processing = False
    cleanup_video_capture()
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ
    if logger:
        logger.log_event(
            EventType.INFO,
            "–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞",
            {}
        )
    
    return jsonify({'status': 'success', 'message': '–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'})

@app.route('/api/upload_video', methods=['POST'])
def upload_video():
    try:
        if 'video' not in request.files:
            return jsonify({'status': 'error', 'message': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'})
        
        video_file = request.files['video']
        if video_file.filename == '':
            return jsonify({'status': 'error', 'message': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'})
        
        allowed_extensions = {'mp4', 'avi', 'mov', 'mkv', 'webm'}
        file_extension = video_file.filename.lower().split('.')[-1]
        if file_extension not in allowed_extensions:
            return jsonify({'status': 'error', 'message': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–∏–¥–µ–æ'})
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        temp_dir = tempfile.gettempdir()
        filename = f"uploaded_video_{uuid.uuid4().hex}.{file_extension}"
        file_path = os.path.join(temp_dir, filename)
        video_file.save(file_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª –º–æ–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å
        test_cap = cv2.VideoCapture(file_path)
        if not test_cap.isOpened():
            os.remove(file_path)
            return jsonify({'status': 'error', 'message': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª'})
        
        test_cap.release()
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ
        if logger:
            logger.log_event(
                EventType.INFO,
                f"–ó–∞–≥—Ä—É–∂–µ–Ω –≤–∏–¥–µ–æ—Ñ–∞–π–ª: {filename}",
                {'filename': filename, 'file_path': file_path}
            )
        
        return jsonify({
            'status': 'success', 
            'message': '–í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ',
            'file_path': file_path,
            'filename': filename
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}'})

@app.route('/api/metrics')
def get_metrics():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –º–µ—Ç—Ä–∏–∫"""
    with frame_lock:
        return jsonify(current_metrics)

@app.route('/api/violations')
def get_violations():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –Ω–∞—Ä—É—à–µ–Ω–∏–π"""
    with frame_lock:
        violations = current_metrics.get('active_violations', [])
        return jsonify(violations)

@app.route('/api/events')
def get_events():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π –∏–∑ –ª–æ–≥–∞"""
    if logger:
        events = logger.get_recent_events(5)
        return jsonify(events)
    return jsonify([])

@app.route('/api/health')
def health_check():
    """API –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
    return jsonify({
        'status': 'healthy',
        'processing': processing,
        'video_source': video_source,
        'components_initialized': components_initialized,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/debug_info')
def debug_info():
    """API –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    debug_info = {
        'processing': processing,
        'video_source': video_source,
        'current_video_path': current_video_path,
        'components_initialized': components_initialized,
        'current_frame_available': current_frame is not None,
        'cap_initialized': cap is not None and cap.isOpened() if cap else False,
        'timestamp': datetime.now().isoformat()
    }
    
    if cap and cap.isOpened():
        debug_info.update({
            'cap_width': cap.get(cv2.CAP_PROP_FRAME_WIDTH),
            'cap_height': cap.get(cv2.CAP_PROP_FRAME_HEIGHT),
            'cap_fps': cap.get(cv2.CAP_PROP_FPS),
            'cap_frame_count': cap.get(cv2.CAP_PROP_FRAME_COUNT) if video_source == 'video_file' else 'N/A'
        })
    
    return jsonify(debug_info)

@app.route('/api/test_detection')
def test_detection():
    """API –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏"""
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∫–∞–¥—Ä
        test_frame = generate_test_frame(0)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
        detections = detector.detect(test_frame)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç—Ä–µ–∫–µ—Ä
        tracks = tracker.update(detections, test_frame)
        
        return jsonify({
            'success': True,
            'detections_count': len(detections),
            'tracks_count': len(tracks),
            'detections': [{'bbox': det['bbox'], 'confidence': det['confidence']} for det in detections],
            'tracks': [{'track_id': track['track_id'], 'center': track['center']} for track in tracks]
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π –¥–∏—Å—Ç–∞–Ω—Ü–∏–∏")
    print("=" * 50)
    print("üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ endpoints:")
    print("  http://localhost:5000 - Web –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å")
    print("  http://localhost:5000/api/current_frame - –¢–µ–∫—É—â–∏–π –∫–∞–¥—Ä —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏")
    print("  http://localhost:5000/api/health - –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
    print("  http://localhost:5000/api/debug_info - –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    print("  http://localhost:5000/api/test_detection - –¢–µ—Å—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏")
    print("\nüéÆ –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print("  1. –û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:5000")
    print("  2. –í—ã–±–µ—Ä–∏—Ç–µ '–¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º'")
    print("  3. –ù–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏'")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –∫–∞–¥—Ä
    initial_frame = generate_test_frame(0)
    success, buffer = cv2.imencode('.jpg', initial_frame)
    if success:
        with frame_lock:
            current_frame = buffer.tobytes()
    
    app.run(host='0.0.0.0', port=5000, debug=True, threaded=True)